let socket;
let mediaRecorder;
let audioChunks = [];
let selectedGender = "Neutral";
let isOutputMic = false;


window.onload = function () {
    setupDropdown("inputLanguageDropdown", "inputFlag", "inputLanguageText");
    setupDropdown("outputLanguageDropdown", "outputFlag", "outputLanguageText");
    setupWebSocket();
};

function setupDropdown(dropdownId, flagId, textId) {
    const dropdown = document.getElementById(dropdownId);
    const selected = dropdown.querySelector(".selected");
    const dropdownMenu = dropdown.querySelector(".dropdown-menu");

    selected.addEventListener("click", (event) => {
        event.stopPropagation();
        dropdownMenu.style.display = dropdownMenu.style.display === "flex" ? "none" : "flex";
    });

    dropdownMenu.querySelectorAll("div").forEach(option => {
        option.addEventListener("click", () => {
            document.getElementById(flagId).src = `https://flagcdn.com/w40/${option.dataset.flag}.png`;
            document.getElementById(textId).textContent = option.textContent.trim();
            dropdownMenu.style.display = "none";
        });
    });

    document.addEventListener("click", (e) => {
        if (!dropdown.contains(e.target)) {
            dropdownMenu.style.display = "none";
        }
    });
}

function toggleGenderDropdown() {
    const menu = document.querySelector(".gender-dropdown-menu");
    menu.style.display = menu.style.display === "flex" ? "none" : "flex";
}

function setGender(gender) {
    selectedGender = gender;
    document.getElementById("selectedGender").textContent = gender;
    document.querySelector(".gender-dropdown-menu").style.display = "none";
}

function setupWebSocket() {
    socket = io.connect();

    socket.on("connect", () => {
        console.log("âœ… WebSocket connected");
    });

    socket.on("transcription_result", async (data) => {
      const inputLang = document.getElementById("inputLanguageText").textContent.trim();
      const outputLang = document.getElementById("outputLanguageText").textContent.trim();
      const sourceLang = isOutputMic ? outputLang : inputLang;
      const targetLang = isOutputMic ? inputLang : outputLang;

      console.log(`ðŸ“ Received transcription: ${data.text}`);
      console.log(`ðŸ” Translating from ${sourceLang} â†’ ${targetLang}`);

      const translated = await translateText(data.text, sourceLang, targetLang);

        await speakText(translated);

        setTimeout(() => {
            document.querySelector(".form-image").classList.remove("slowing");
        }, 1000);
    });

    socket.on("transcription_error", (error) => {
        console.error("âŒ Transcription error:", error);
    });
}

async function startRecording(button) {
  isOutputMic = button.classList.contains("output-mic");
    const image = document.querySelector(".form-image");
    image.classList.remove("slowing");
    image.classList.add("recording");
    button.classList.remove("input-idle", "output-idle");
    button.classList.add("recording");


    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        mediaRecorder = new MediaRecorder(stream, {
            mimeType: "audio/webm;codecs=opus"
        });
        audioChunks = [];

        mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            const blob = new Blob(audioChunks, { type: "audio/webm" });

            const reader = new FileReader();
            reader.onloadend = () => {
                const arrayBuffer = reader.result;
                const buffer = new Uint8Array(arrayBuffer);
                const lang = button.classList.contains("output-mic")
                    ? document.getElementById("outputLanguageText").textContent.trim()
                    : document.getElementById("inputLanguageText").textContent.trim();

                try {
                    socket.emit("stream_audio", {
                        audio: Array.from(buffer),
                        source_lang: lang
                    });
                } catch (err) {
                    console.error("âŒ WebSocket Emit Error:", err);
                }

                image.classList.remove("recording");
                image.classList.add("slowing");
                setTimeout(() => {
                    image.classList.remove("slowing");
                }, 1500);
            };

            reader.readAsArrayBuffer(blob);
        };

        mediaRecorder.start();
    } catch (err) {
        console.error("âŒ Microphone access error:", err);
        alert("Microphone access is blocked or denied.");
        button.classList.remove("recording");
        image.classList.remove("recording");
    }
}

function stopRecording(button) {
  button.classList.remove("recording");

  // âœ¨ Reset idle styles using CSS classes
  if (button.classList.contains("output-mic")) {
    button.classList.add("output-idle");
    button.classList.remove("input-idle");
  } else {
    button.classList.add("input-idle");
    button.classList.remove("output-idle");
  }

  if (mediaRecorder && mediaRecorder.state !== "inactive") {
    mediaRecorder.stop();
  }
}




async function translateText(text, sourceLang, targetLang) {
    try {
        const res = await fetch("/translate", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
                text,
                source_lang: sourceLang,
                target_lang: targetLang,
                gender: selectedGender
            })
        });
        const data = await res.json();
        return data.translated_text || "";
    } catch (err) {
        console.error("âŒ Translation failed:", err);
        document.querySelector(".form-image").classList.remove("recording", "slowing");
        return "";
    }
}

async function speakText(text) {
    let voiceModel = "fable";
    if (selectedGender === "Male") voiceModel = "onyx";
    else if (selectedGender === "Female") voiceModel = "nova";

    try {
        const response = await fetch("/speak", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ input: text, voice: voiceModel })
        });

        const audioBlob = await response.blob();
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        setTimeout(() => audio.play(), 150);
    } catch (err) {
        console.error("âŒ Speech generation failed:", err);
    }
}

document.addEventListener("click", function (e) {
    const dropdown = document.querySelector(".gender-dropdown");
    const menu = document.querySelector(".gender-dropdown-menu");
    if (!dropdown.contains(e.target)) {
        menu.style.display = "none";
    }
});

document.addEventListener("DOMContentLoaded", () => {
  const inputMicButton = document.querySelector(".mic-button:not(.output-mic)");
  const outputMicButton = document.querySelector(".mic-button.output-mic");

  // âœ… Set initial idle state styles
  inputMicButton.classList.add("input-idle");
  outputMicButton.classList.add("output-idle");

  inputMicButton.addEventListener("click", () => {
    if (inputMicButton.classList.contains("recording")) {
      stopRecording(inputMicButton);
    } else {
      startRecording(inputMicButton);
    }
  });

  outputMicButton.addEventListener("click", () => {
    if (outputMicButton.classList.contains("recording")) {
      stopRecording(outputMicButton);
    } else {
      startRecording(outputMicButton);
    }
  });
});

async function requestMicrophonePermissionEarly() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log("âœ… Early microphone permission granted.");
        stream.getTracks().forEach(track => track.stop());
    } catch (err) {
        console.error("âŒ Microphone permission blocked or denied on load:", err);
    }
}

window.addEventListener("load", requestMicrophonePermissionEarly);

function showPricingToast() {
  const toast = document.getElementById("pricing-toast");
  toast.classList.remove("hidden");
}

function hidePricingToast() {
  const toast = document.getElementById("pricing-toast");
  toast.classList.add("hidden");
}

function selectPlan(planType) {
  hidePricingToast();
  alert(`ðŸ‘‰ Selected: ${planType.toUpperCase()}`);
  // Later: trigger Android billing, token granting, etc.
}

// ðŸ§ª TEMPORARY VISUAL TEST FUNCTION
function testToastOnLoad() {
  window.addEventListener("load", () => {
    showPricingToast(); // This will ONLY run visually for now
  });
}

testToastOnLoad(); // Call this separately, won't interfere with anything else






